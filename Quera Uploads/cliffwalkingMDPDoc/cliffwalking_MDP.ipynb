{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b65fb03",
   "metadata": {},
   "source": [
    "### Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674ac327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from gymnasium.envs.toy_text.cliffwalking import CliffWalkingEnv\n",
    "from gymnasium.error import DependencyNotInstalled\n",
    "from os import path\n",
    "from time import time\n",
    "\n",
    "# Do not change this class\n",
    "UP = 0\n",
    "RIGHT = 1\n",
    "DOWN = 2\n",
    "LEFT = 3\n",
    "image_path = path.join(path.dirname(gym.__file__), \"envs\", \"toy_text\")\n",
    "\n",
    "\n",
    "class CliffWalking(CliffWalkingEnv):\n",
    "    def __init__(self, is_hardMode=True, num_cliffs=10, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.is_hardMode = is_hardMode\n",
    "\n",
    "        # Generate random cliff positions\n",
    "        if self.is_hardMode:\n",
    "            self.num_cliffs = num_cliffs\n",
    "            self._cliff = np.zeros(self.shape, dtype=bool)\n",
    "            self.start_state = (3, 0)\n",
    "            self.terminal_state = (self.shape[0] - 1, self.shape[1] - 1)\n",
    "            self.cliff_positions = []\n",
    "            while len(self.cliff_positions) < self.num_cliffs:\n",
    "                new_row = np.random.randint(0, 4)\n",
    "                new_col = np.random.randint(0, 11)\n",
    "                state = (new_row, new_col)\n",
    "                if (\n",
    "                        (state not in self.cliff_positions)\n",
    "                        and (state != self.start_state)\n",
    "                        and (state != self.terminal_state)\n",
    "                ):\n",
    "                    self._cliff[new_row, new_col] = True\n",
    "                    if not self.is_valid():\n",
    "                        self._cliff[new_row, new_col] = False\n",
    "                        continue\n",
    "                    self.cliff_positions.append(state)\n",
    "\n",
    "        # Calculate transition probabilities and rewards\n",
    "        self.P = {}\n",
    "        for s in range(self.nS):\n",
    "            position = np.unravel_index(s, self.shape)\n",
    "            self.P[s] = {a: [] for a in range(self.nA)}\n",
    "            self.P[s][UP] = self._calculate_transition_prob(position, [-1, 0])\n",
    "            self.P[s][RIGHT] = self._calculate_transition_prob(position, [0, 1])\n",
    "            self.P[s][DOWN] = self._calculate_transition_prob(position, [1, 0])\n",
    "            self.P[s][LEFT] = self._calculate_transition_prob(position, [0, -1])\n",
    "\n",
    "    def _calculate_transition_prob(self, current, delta):\n",
    "        new_position = np.array(current) + np.array(delta)\n",
    "        new_position = self._limit_coordinates(new_position).astype(int)\n",
    "        new_state = np.ravel_multi_index(tuple(new_position), self.shape)\n",
    "        if self._cliff[tuple(new_position)]:\n",
    "            return [(1.0, self.start_state_index, -100, False)]\n",
    "\n",
    "        terminal_state = (self.shape[0] - 1, self.shape[1] - 1)\n",
    "        is_terminated = tuple(new_position) == terminal_state\n",
    "        return [(1 / 3, new_state, -1, is_terminated)]\n",
    "\n",
    "    # DFS to check that it's a valid path.\n",
    "    def is_valid(self):\n",
    "        frontier, discovered = [], set()\n",
    "        frontier.append((3, 0))\n",
    "        while frontier:\n",
    "            r, c = frontier.pop()\n",
    "            if not (r, c) in discovered:\n",
    "                discovered.add((r, c))\n",
    "                directions = [(1, 0), (0, 1), (-1, 0), (0, -1)]\n",
    "                for x, y in directions:\n",
    "                    r_new = r + x\n",
    "                    c_new = c + y\n",
    "                    if r_new < 0 or r_new >= self.shape[0] or c_new < 0 or c_new >= self.shape[1]:\n",
    "                        continue\n",
    "                    if (r_new, c_new) == self.terminal_state:\n",
    "                        return True\n",
    "                    if not self._cliff[r_new][c_new]:\n",
    "                        frontier.append((r_new, c_new))\n",
    "        return False\n",
    "\n",
    "    def step(self, Action):\n",
    "        if Action not in [0, 1, 2, 3]:\n",
    "            raise ValueError(f\"Invalid action {Action}   must be in [0, 1, 2, 3]\")\n",
    "\n",
    "        if self.is_hardMode:\n",
    "            match Action:\n",
    "                case 0:\n",
    "                    Action = np.random.choice([0, 1, 3], p=[1 / 3, 1 / 3, 1 / 3])\n",
    "                case 1:\n",
    "                    Action = np.random.choice([0, 1, 2], p=[1 / 3, 1 / 3, 1 / 3])\n",
    "                case 2:\n",
    "                    Action = np.random.choice([1, 2, 3], p=[1 / 3, 1 / 3, 1 / 3])\n",
    "                case 3:\n",
    "                    Action = np.random.choice([0, 2, 3], p=[1 / 3, 1 / 3, 1 / 3])\n",
    "\n",
    "        return super().step(Action)\n",
    "\n",
    "    def _render_gui(self, mode):\n",
    "        try:\n",
    "            import pygame\n",
    "        except ImportError as e:\n",
    "            raise DependencyNotInstalled(\n",
    "                \"pygame is not installed, run `pip install gymnasium[toy-text]`\"\n",
    "            ) from e\n",
    "        if self.window_surface is None:\n",
    "            pygame.init()\n",
    "\n",
    "            if mode == \"human\":\n",
    "                pygame.display.init()\n",
    "                pygame.display.set_caption(\"CliffWalking - Edited by Audrina & Kian\")\n",
    "                self.window_surface = pygame.display.set_mode(self.window_size)\n",
    "            else:  # rgb_array\n",
    "                self.window_surface = pygame.Surface(self.window_size)\n",
    "        if self.clock is None:\n",
    "            self.clock = pygame.time.Clock()\n",
    "        if self.elf_images is None:\n",
    "            hikers = [\n",
    "                path.join(image_path, \"img/elf_up.png\"),\n",
    "                path.join(image_path, \"img/elf_right.png\"),\n",
    "                path.join(image_path, \"img/elf_down.png\"),\n",
    "                path.join(image_path, \"img/elf_left.png\"),\n",
    "            ]\n",
    "            self.elf_images = [\n",
    "                pygame.transform.scale(pygame.image.load(f_name), self.cell_size)\n",
    "                for f_name in hikers\n",
    "            ]\n",
    "        if self.start_img is None:\n",
    "            file_name = path.join(image_path, \"img/stool.png\")\n",
    "            self.start_img = pygame.transform.scale(\n",
    "                pygame.image.load(file_name), self.cell_size\n",
    "            )\n",
    "        if self.goal_img is None:\n",
    "            file_name = path.join(image_path, \"img/cookie.png\")\n",
    "            self.goal_img = pygame.transform.scale(\n",
    "                pygame.image.load(file_name), self.cell_size\n",
    "            )\n",
    "        if self.mountain_bg_img is None:\n",
    "            bg_image = [\n",
    "                path.join(image_path, \"img/mountain_bg1.png\"),\n",
    "                path.join(image_path, \"img/mountain_bg2.png\"),\n",
    "            ]\n",
    "            self.mountain_bg_img = [\n",
    "                pygame.transform.scale(pygame.image.load(f_name), self.cell_size)\n",
    "                for f_name in bg_image\n",
    "            ]\n",
    "        if self.near_cliff_img is None:\n",
    "            near_cliff_image = [\n",
    "                path.join(image_path, \"img/mountain_near-cliff1.png\"),\n",
    "                path.join(image_path, \"img/mountain_near-cliff2.png\"),\n",
    "            ]\n",
    "            self.near_cliff_img = [\n",
    "                pygame.transform.scale(pygame.image.load(f_name), self.cell_size)\n",
    "                for f_name in near_cliff_image\n",
    "            ]\n",
    "        if self.cliff_img is None:\n",
    "            file_name = path.join(image_path, \"img/mountain_cliff.png\")\n",
    "            self.cliff_img = pygame.transform.scale(\n",
    "                pygame.image.load(file_name), self.cell_size\n",
    "            )\n",
    "\n",
    "        for s in range(self.nS):\n",
    "            row, col = np.unravel_index(s, self.shape)\n",
    "            pos = (col * self.cell_size[0], row * self.cell_size[1])\n",
    "            check_board_mask = row % 2 ^ col % 2\n",
    "            self.window_surface.blit(self.mountain_bg_img[check_board_mask], pos)\n",
    "\n",
    "            if self._cliff[row, col]:\n",
    "                self.window_surface.blit(self.cliff_img, pos)\n",
    "            if s == self.start_state_index:\n",
    "                self.window_surface.blit(self.start_img, pos)\n",
    "            if s == self.nS - 1:\n",
    "                self.window_surface.blit(self.goal_img, pos)\n",
    "            if s == self.s:\n",
    "                elf_pos = (pos[0], pos[1] - 0.1 * self.cell_size[1])\n",
    "                last_action = self.lastaction if self.lastaction is not None else 2\n",
    "                self.window_surface.blit(self.elf_images[last_action], elf_pos)\n",
    "\n",
    "        if mode == \"human\":\n",
    "            pygame.event.pump()\n",
    "            pygame.display.update()\n",
    "            self.clock.tick(self.metadata[\"render_fps\"])\n",
    "        else:  # rgb_array\n",
    "            return np.transpose(\n",
    "                np.array(pygame.surfarray.pixels3d(self.window_surface)), axes=(1, 0, 2)\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ae8828",
   "metadata": {},
   "source": [
    "### Create an environment as human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e174eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = CliffWalking(render_mode=\"human\")\n",
    "observation, info = env.reset(seed=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb7926b",
   "metadata": {},
   "source": [
    "### Create an environment as robot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb732974",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = CliffWalking()\n",
    "observation, info = env.reset(seed=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234d7af9",
   "metadata": {},
   "source": [
    "### Preapare traps list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39dc74b",
   "metadata": {
    "direction": "rtl"
   },
   "source": [
    "شماره خانه های صخره درون لیست traps ذخیره می شود."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6658ac00",
   "metadata": {},
   "outputs": [],
   "source": [
    "traps = [float(i[0] * 12 + i[1]) for i in env.cliff_positions]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8190e0e8",
   "metadata": {},
   "source": [
    "### Prepare States Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a423cce",
   "metadata": {
    "direction": "rtl"
   },
   "source": [
    "از دیکسشنری states برای محاسبات استفاده می کنیم.\n",
    "در اینجا مقادیر اولیه آن را تعریف کرده ایم."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4ed058",
   "metadata": {},
   "outputs": [],
   "source": [
    "states = dict()\n",
    "for i in range(0, 4):\n",
    "    for j in range(0, 12):\n",
    "        if i * 12 + j in traps:\n",
    "            states[i * 12 + j] = -100\n",
    "        elif i == 3 and j == 11:\n",
    "            states[i * 12 + j] = 1000\n",
    "        else:\n",
    "            states[i * 12 + j] = {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8f0d4e",
   "metadata": {},
   "source": [
    "### Calculate score for each state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba018e2f",
   "metadata": {
    "direction": "rtl"
   },
   "source": [
    "این تابع ارزش خوانه فراخوانی شده را برمیگرداند. بدین صورت که در صورت بودن هدف و یا صخره مستقیما امتیاز آن برگشت داده می شود و در غیر اینصورت مقدار بیشترین عمل برگشت داده می شود."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239a93d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateScore(inp):\n",
    "    global states\n",
    "    return max(states[inp].values()) if isinstance(states[inp], type(dict())) else states[inp]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7ec57e",
   "metadata": {},
   "source": [
    "### Used for update score of an action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beab7afb",
   "metadata": {
    "direction": "rtl"
   },
   "source": [
    "از این تابع برای اپدیت مقدار ارزش هر عمل استفاده می شود و مقدار بازگشت داده شده مقدار تغییرات آن است."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fbe3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def changeScore(kp, ks, v1, v2, v3):\n",
    "    global states\n",
    "    score = (v1 + v2 + v3) / 3\n",
    "    change = score - states[kp][ks]\n",
    "    states[kp][ks] = score\n",
    "    return abs(change)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a6f427",
   "metadata": {},
   "source": [
    "### Main update states fundtion in MDP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d0f203",
   "metadata": {
    "direction": "rtl"
   },
   "source": [
    "این تابع اصلی برای بروز کردن مقادیر states است.\n",
    "بدین صورت که با هر بار اجرا بصورت مستقل عملکرد و هر خانه و عمل های آن را ارزشگذاری و مقدار کل تغییرات را برمیگرداند.\n",
    "پس از پیمایش states درصورتی که خانه صخره و یا هدف نبود، موقعیت بعدی آن را از هر سمت به دست می آوریم و سپس امتیاز اعمال را با استفاده از توابع بالا بروز رسانی می کنیم."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7304bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateState():\n",
    "    global states\n",
    "    totalChanges = 0\n",
    "    for Key, Val in states.items():\n",
    "        if isinstance(Val, type(dict())):\n",
    "            row = Key // 12\n",
    "            col = Key % 12\n",
    "            up = row * 12 + col if row == 0 else (row - 1) * 12 + col\n",
    "            right = row * 12 + col if col == 11 else row * 12 + col + 1\n",
    "            down = row * 12 + col if row == 3 else (row + 1) * 12 + col\n",
    "            left = row * 12 + col if col == 0 else row * 12 + col - 1\n",
    "            for Ks, Vs in Val.items():\n",
    "                upScore = calculateScore(up)\n",
    "                rightScore = calculateScore(right)\n",
    "                leftScore = calculateScore(left)\n",
    "                downScore = calculateScore(down)\n",
    "\n",
    "                if Ks == 0:\n",
    "                    totalChanges += changeScore(Key, Ks, upScore, rightScore, leftScore)\n",
    "                elif Ks == 1:\n",
    "                    totalChanges += changeScore(Key, Ks, upScore, rightScore, downScore)\n",
    "                elif Ks == 2:\n",
    "                    totalChanges += changeScore(Key, Ks, leftScore, rightScore, downScore)\n",
    "                elif Ks == 3:\n",
    "                    totalChanges += changeScore(Key, Ks, upScore, rightScore, downScore)\n",
    "    return totalChanges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e857523a",
   "metadata": {},
   "source": [
    "### Handle updating states"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6661edb",
   "metadata": {
    "direction": "rtl"
   },
   "source": [
    "این حلقه همان حلقه معروف فرایند مارکوف است که در صورت کم نشدن مقدار تغییرات هزار بار تابع updateState را فراخوانی و مقدار states را بروز می کند.\n",
    "بعد از آن policies را با استفاده از states ایجاد کرده ایم، بدین صورت که با ارزش ترین عمل انتخواب می شود. \n",
    "در نهایت برای اینکه خانه 47 خانه هدف است حساب نشده که برای رفع باگ مقدار 1 (حرکت به راست) را برای آن قرارداده ایم."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080c09be",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000\n",
    "changes = updateState()\n",
    "\n",
    "while n > 0 and changes > 0.005:\n",
    "    changes = updateState()\n",
    "    n -= 1\n",
    "\n",
    "policies = dict()\n",
    "for Kp, Vp in states.items():\n",
    "    if isinstance(Vp, type(dict())):\n",
    "        Kmax = 1\n",
    "        VMax = Vp[1]\n",
    "        for K, V in Vp.items():\n",
    "            if V > VMax:\n",
    "                Kmax = K\n",
    "                VMax = V\n",
    "        policies[Kp] = Kmax\n",
    "\n",
    "policies[47] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc878bd",
   "metadata": {},
   "source": [
    "### Run envirment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee83e33",
   "metadata": {
    "direction": "rtl"
   },
   "source": [
    "با قرار دادن policies در کد کار به اتمام می رسد. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5ba02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the maximum number of iterations\n",
    "max_iter_number = 1000\n",
    "next_state = 36\n",
    "winRate = 0\n",
    "sumRewards = 0\n",
    "for __ in range(max_iter_number):\n",
    "    # TODO: Implement the agent policy here\n",
    "    # Note: .sample() is used to sample random Action from the environment's Action space\n",
    "\n",
    "    # Choose an Action (Replace this random Action with your agent's policy)\n",
    "    # Action = env.action_space.sample()\n",
    "    action = policies[next_state]\n",
    "\n",
    "    # Perform the Action and receive feedback from the environment\n",
    "    next_state, reward, done, truncated, info = env.step(action)\n",
    "\n",
    "    sumRewards += reward\n",
    "\n",
    "    if done:\n",
    "        winRate += 1\n",
    "        sumRewards += 1000\n",
    "\n",
    "    if done or truncated:\n",
    "        observation, info = env.reset()\n",
    "\n",
    "# Close the environment\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51bbd5d7",
   "metadata": {},
   "source": [
    "# End"
   ]
  }
 ],
 "metadata": {
  "direction": "ltr",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
